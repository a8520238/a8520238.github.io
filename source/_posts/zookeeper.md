---
title: zookeeper
date: 2021-2-28
cover:
top_img:
categories: 分布式
tags: 
mathjax: true
katex: true
---
# 1 zookeeper
[zookeeper+Dubbo](https://www.bilibili.com/video/BV1BA411q7ia?p=31)

包括数据发布订阅、负载均衡、命名服务、集群管理分布式锁、分布式队列等功能。

1. zookeeper提供了分布式数据一致性解决方案

一致性：
- 强一致性：锁机制、如果数据不一致，不提供服务
- 最终一致性：数据最终同步即可，没有实时性要求

2. CAP原则（一致性、可用性和分区容错性）
- 一致性：指的是强一致性 (C)
- 可用性：服务一直处于可用状态 (A)
- 分区容错性：在遇到任何网络分区故障，仍需要对外提供一致性和可用性服务。(P)
3选2， 要么AP 要么CP

2. 一致性协议
    - 2PC二阶段提交
        - 阶段一预执行，但事务没有提交
        - 阶段二执行事务提交或者中断事务，如果所有参与者都返回ack，则执行事务，否则中断
        > 这一个过程需要协调者
<br>

    - 二阶段提交的问题
        - 同步阻塞：协调者发送消息后需要阻塞
        - 单点：如果协调者挂了，就完了
        - 脑裂导致数据不一致：如果协调者与某个节点断开，有些节点提交了，有些没有不一致
    - 3PC阶段提交
        - 阶段1，协调者向所有参与者发送canCommit询问，能否响应事务请求，相当于网络测试
        - 阶段2，如果阶段1所有节点都能通讯，所有都执行预提交，也就是preCommit操作预提交，如果某个节点返回no或等待超时，则则中断事务。
        - 阶段3，doCommit，如果所有阶段2都成功，执行提交，发送提交请求，否则中断事务。
    - 3PC解决了同步阻塞和单点问题，一个是超时时间解决同步阻塞，一个是如果协调者在三阶段挂了，其他节点没收到commit会自动提交
3. paxos算法
    - 基于消息传递且具有高度容错性的一种算法，是目前公认的解决分布式一致性问题的最有效的算法。
    - 解决问题，在分布式系统中，如果产生宕机或网络异常，快速的正确的在集群内部解决数据一致性问题（过半理念）zookeeper基于 fast paxos版本
    - paxos中的四个角色
        - client：产生提案者
        - peoposer：提案者
        - acceptor：决策者
        - learners: 学习者（只遵循最后的结果）
    - paxos分为两个阶段
        - 阶段1：prepare阶段：准备解决
        - 阶段2：accept阶段：同意阶段
    - prepare阶段
        - proposer做出一个提案，编号为n发送给所有acceptor。
        - 第一次接受prepare请求：maxN被保存，同时响应
        - 不是第一次，每个决策者保存一个最大提案号maxN,如果n小于maxN，证明提案已过时，拒绝。如果大于maxN，更新maxN，进行响应。
        - 如果收到的响应过半，立刻进入第二阶段。
    - accept阶段
        - 传递编号n和value， (n, value)，如果n大于等于maxN,同意提案，进行响应。如果小于，那么拒绝提案，不会响应。
    1.  活锁问题（解决办法，执行时间稍稍错开）
4. zookeeper 使用的是ZAB（Fast Paxos），因为Paxos存在活锁和全序的问题
- ZAB（zookeeper atomic broadcast）：是一种支持崩溃恢复的原子广播协议
- Zookeeper使用单一主进程Leader处理客户端发送过来的所有事务请求（写清求）。当服务器数据发生变更后，会把请求包装成提案，发送给所有follower，只要follower达到半数，同意请求，之后leader通知所有follower，进行同步数据。读请求的话，leader会自己响应。
- 如果客户端发送到follower上的话，如果是读请求，follwer自己响应，否则是写清求的话，会将请求转发给leader，走leader的流程。
5. zookeeper的三种角色
- leader：主要负责处理集群的写清求，并发起投票，只有超过半数的节点同意后才会提交该写请求
- follower：处理读请求，响应结果。转发写清求得到leader,并在选举leader过程中参与投票。
- observer：可以理解为没有投票权的follower，主要职责是协助follower处理读请求，当整个zk集群读请求负载很高时，增加。如果增加follower会增加写请求负载，因为follower也要投票。
5. zookeeper两种模式
- 恢复模式：当服务启动或领导崩溃后，zk进入恢复状态，选举leader，leader选出后，完成leader和其他机器的同步，当大多数server完成和leader的同步后，恢复模式结束。
- 广播模式：一旦leader已经和多数的Follower进行了状态同步后，进入广播模式。进入广播模式后，如果有新加入的服务器，会自动从leader中同步数据。leader在接收客户端请求后，会生成事务提案广播给其他机器，有超过半数以上的follower同意该提议后，再提交事务。
- 在ZAB的事务的二阶段提交中，移除了事务的中断，要么ack，要么放弃，leader无需等待所有的follower的ack.
6. zxid
- zxid是64位长度的Long类型，其中高32位表示纪元epoch，低32位表示事务标识xid
7. leader选举原则
    1. zookeeper集群只有超过了半数以上的服务器启动，集群才能正常工作
    2. 在集群正常工作之前，myid小的服务器会给myid大服务器进行投票，持续到集群正常工作，选出leader
    3. 选出leader之后，之前的服务器的状态由looking改变为following,之后的服务器都是follower
8. zab解决全序问题，因为事务执行顺序不同，导致结果不同，leader会创建一个队列，保证最终结果。

> 相关操作

> 1. ls path watch 监听节点子节点的变化

> 2. get path watch 监听节点值的变化

> 3. 监听的有效期只有一次

# 2 应用场景
1. 配置中心
- 把配置信息存在节点中，通过监听来同步
2. 负载均衡
- 新增服务器，让nginx知道服务器列表的更新。通过监听器监视servers子节点的状态变化。
3. 命名服务
- 创建顺序节点保证唯一标识
4. DNS服务
5. 集群管理
    1. 集群控制：对集群中节点进行操作与控制
    2. 集群监控：对集群节点运行状态的收集
- zookeeper集群管理主要利用了watcher机制和创建临时节点来实现。比如机器上下线：
    - 新增机器的时候，将Agent部署到新增的机器上，当Agent部署启动时，会向zookeeper指定的节点下创建一个临时子节点，通过监视器，对机器的上下线进行监控。
    - 当子节点创建完成后，机器会接受到"子节点变更事件"，即上限通知，就可以对新加入的机器开启相应的后台管理逻辑。监控中心同样可以获得到机器的运行状态信息。
6. 分布式锁
    1. 数据库实现分布式锁，让不同的服务器操作同一个数据库。使用dblock.lock();添加一条记录，lock_name:db_lock_stock。注意这个lock_name是惟一的，如果已经存在，需要阻塞。
    2. redis实现分布式锁，基于setnx（set if not exists），设置成功返回1，否则返回0.要注意设置过期时间，防止异常，expire name time。redis为了解决单点问题，官方推出了分布式锁redlock
    3. zookeeper实现分布式锁
        - 原理：创建有序临时节点+watch监听来实现。每一个执行的线程创建一个有序的临时节点，为了确保有序性，在创建完节点，会再获取全部节点，再重新进行一次排序，排序过程中，每个线程要判断自己剩下的临时节点的序号是否是最小的。如果是最小的，将会获取到锁，执行相关操作，释放锁。如果不是最小的，会监听它的前一个节点，当它的前一个节点被删除时，它就会获得锁，依次类推。
7. 分布式队列：跟分布式锁相似，监听之前的节点是否出列