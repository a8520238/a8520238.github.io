---
title: 内存管理
date: 2021-2-28
cover:
top_img:
categories: 操作系统
tags: 
mathjax: true
katex: true
---
[操作系统内存管理](https://juejin.cn/post/6844903490196619272)

[图解内存管理](https://blog.csdn.net/qq_29677867/article/details/91038642?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control#121__49)(重点)
# 1 存储区体系

主存（RAM）是一件非常重要的资源，不管存储器有多大，程序大小的增长速度比内存容量的增长速度要快的多。

## 1.1 分层存储器体系(memory hierarchy)
![存储层次结构](http://note.youdao.com/yws/public/resource/eed1fa7701b0e40871bca24194444756/xmlnote/DCDF99335BF54511A72AC2890C6F17FD/14946)

## 1.2 无存储抽象

将物理内存暴露给进程的缺点：
1. 如果用户程序可以寻址内存的每个字节，他们就可以很容易的破坏操作系统，从而使系统停止运行。
2. 难以运行多个程序（地址冲突）

# 2 内存管理
> MMU(内存管理单元)：硬件组件负责处理CPU的内存访问请求

## 2.1 目的
更好的支持多道程序并发执行，提高系统性能。进程之间共享的不仅仅是处理机，还有主存储器。如果不对内存进行管理，容易导致内存数据的混乱。

## 2.2 内存管理功能
- 内存空间的分配与回收
- 地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址
- 内存空间的扩充：虚拟存储技术或自动覆盖技术，从逻辑上扩充内存
- 存储保护：保证各道作业在各自的存储空间内运行，互不干扰
- 程序装入和链接
## 2.3 逻辑地址空间和物理地址空间
- 编译后，每个目标模块都是从0号单元开始编址（逻辑地址），链接程序顺序依次按各个模块的相对地址构成从0号单元开始编址的逻辑地址空间。
- 物理地址空间指内存中物理单元的集合。通过物理地址在主存中存取数据。
- 当装入程序将可执行代码装入内存时，必须通过地址转换讲逻辑地址转换成物理地址，这个过程称为地址重定位
## 2.4 内存保护

内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。
- 设置上下限寄存器存放主存中的上下限地址判断是否越界。
- 采用重定位寄存器（基址寄存器，存放最小的物理地址值）和界地址寄存器（限长寄存器，存放逻辑地址的最大值）。
# 3 管理方式

## 3.0 逻辑地址与物理地址的转换
1. ALU需要某个逻辑地址的内存的内容
2. 内存管理单元（MMU）寻找在逻辑地址和物理地址之间的映射，如果没有就从内存中找。（操作系统完成）
3. 控制器从总线发送在物理内存内容的请求
4. 内存发送物理地址给CPU

## 3.1 连续分配管理方式
1. 单一连续分配：分配到内存固定区域，只适合单任务系统
2. 固定分区分配：分配到内存中不同的固定区域，分区可以相等也可以不相等。内部碎片（已经被分配出去（能明确是哪个线程），却不能被利用的内存空间）
    - 内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。
3. 动态分区分配：按程序的需要进程动态划分。外部碎片（还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。）
    - 外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。
[外部碎片和内部碎片](https://www.cnblogs.com/sjlove/archive/2013/06/05/3119683.html)
## 3.2 空闲内存管理
在进行内存动态分配时，操作系统必须对其进行管理。一般来说，有两种监控内存使用的方式
- 位图（bitmap）（基于表的）：使用位图方法时，内存被划分为分配单元，每个分配单元对应于位图中的一位，0表示空闲，1表示占用（或者相反）。位图的大小取决于内存和分配单元的大小。
- 位图的分配：找到连续的0。
- 空闲列表（free lists）（基于链的）：维护一个记录已分配内存段和空闲内存段的链表，链表中的一个节点会包含进程或者是两个进程间的空闲区域。
- 空闲列表的分配：（动态分区分配算法）
<br>(如果为进程和空闲区维护各自独立的链表，就能集中精力只检查空闲区而不是进程，但这种分配速度的提高的一个不可避免的代价就是增加复杂度和内存释放速度变慢，因为必须将一个回收的段从进程链表中删除并插入空闲区链表)
    1. 首次适配：从头开始扫描，直到找到一个足够大的空闲区
    2. 下次适配：从上次结束的地方开始扫描
    3. 最佳适配：从头到尾扫描，找到能容纳进程的最小空闲区。会产生大量无用的小缓冲区。
    4. 最差适配：总是分配最大的内存区域（不会分裂出小缓冲区）
    5. 快速适配：为常用大小的空闲区维护单独的链表。
[位图和空闲链表]https://blog.csdn.net/qq_22238021/article/details/80175461)

## 3.3 非连续分配管理方式
对于内存的连续分配，总是会有碎片的产生，内存利用率低，而且执行碎片整理的方法也都是有开销的。因此，非连续内存分配就能很好的解决碎片问题，也是操作系统中用的最多的内存分配方法。
非连续分配（分页/分段）允许一个程序分散地装入到不相邻的内存分区中去。
### 3.3.1 基本分页存储管理方式

[分页分段解释较好](https://zhuanlan.zhihu.com/p/87514615)

内存分为固定的块，按物理结构划分，会有内部碎片
1. 基本概念
    - 页
        - 一定大小字节数内存单元，属于逻辑单元。进程中所有代码、数据等信息均按页进行存储，属于逻辑组织形式。每个页有页码及其他信息。
    - 页框
        - 对应页字节数的物理内存，属于物理单元，是实际存在于物理内存中的可用地址单元。页框相当于页的容器，进程运行过程中，可能会动态加载不同页进入页框，CPU则直接对页框进行存取。
    - 页表
        - 既然有页和对应页框，那就必须有映射表将两者联系起来，而页表就是页和页框之间的映射表。换言之，知道页就可以查询到页框，知道页框，也可以查询到对应页。
    - 进程中的块称为页，内存中的块称为页框，外存以同样的单位进行划分，称为块。进程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框。
    - 地址结构 页号 + 页内偏移量
    - 页表 为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建3立一张页表，记录页面在内存中对应的物理块号。页表一般放在内存中。
2. 基本地址变换机构
<br>页式管理中地址空间是一维的
<br>两个主要问题：
    - 每次访问操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会降低
    - 每个进程引入了页表，用于存储映射机制，页表不能太大，否则内存利用率会降低
3. 具有快表的地址变换机构
- 若页表全部放在内存中，则存取一条数据或指令至少需要访问两次内存：一次访问页表，确定物理地址，第二次存取数据或指令
- 快表/联想寄存器/TLB 在地址变换机构中的一个具有并行查找能力的高速缓冲存储器。用来存放当前访问的若干页表项，以加速地址变换的过程。主存中的页表称为慢表。
4. 两级页表
<br>一级页号+二级页号+页内偏移
5. 分页和分段的区别
    - 页是信息的物理单位，分页是为了减少内存碎片，提高内存利用率。分页仅仅是由于系统管理的需要，而不是用户的需要。段是信息的逻辑单位，它包含一组意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。
    - 页的大小固定且由系统确定，逻辑地址的划分是由寄存器实现的，因而一个系统只能有一种大小的页面。段的长度不固定，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。
    - 分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需要利用一个记忆符，即可表示一个地址。分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。
### 3.3.2 基本分段存储管理模式

内存块的大小不固定，按逻辑结构划分，会有外部碎片。

# 4 内存扩充

## 4.1 覆盖

在较小的内存中运行较大的内存，将没有调用关系的程序放在一个分区。可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分里即将访问的段放进覆盖区，其他段放在外存。
![](http://note.youdao.com/yws/public/resource/375267987e6a5e59121a79328ccdf2bc/xmlnote/BE6AB4C1E94E42FD8718721D3956E4C3/15170)
B，D，E没有调用关系，也就是说，在调用B时，不可能同时调用D或E，所以共享一个覆盖区。早期用这个技术来节约内存。

## 4.2 交换

将暂时不能运行的程序送到外存，从而获得空闲内存空间。粒度是一个程序，需要操作系统支持，对程序员透明。

把处于等待状态的程序从内存移到辅存，把内存空间腾出来（换出）。把准备好竞争CPU运行的程序从辅存移到内存（换入）

1. 覆盖与交换的比较
    - 覆盖只能发生在那些相互之间没有调用关系的程序模块之间。
    - 交换技术是在以内存中的程序大小为单位来进行的，一般一页以上。不需要程序员给出各个模块之间的逻辑覆盖结构。
    - 覆盖和交换都有它的局限性，覆盖过于麻烦，而交换的粒度太大，以程序为单位。所以需要虚拟内存技术。

## 4.3 虚拟内存 

随着软件的不断增大，需要运行的程序往往大到内存无法容纳。应用交换技术并不是很高效（交换几GB的内存）。

虚拟内存使用了外存上的空间来扩充内存的空间，通过一定的换入换出，使得整个系统在逻辑上能够使用一个远远超出其物理内存大小的内存容量。因为虚拟内存技术调换页面时需要访问外存，导致平均访存时间下降，如果使用了不合适的替换算法，则会
大大降低系统性能。
- 虚拟存储器：对物理存储器的抽象，允许程序申请大于实际物理存储的内存，提供一致性的地址空间。基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统讲所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放要掉入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。
- 内存管理单元（Memory Management Unit， MMU），MMU把虚拟地址映射为物理内存地址。

### 4.3.1 局部性原理
- 时间局部性：如果一条指令被执行或某个数据被访问过，那么不久以后该指令可能再次执行，该数据可能再次被访
- 空间局部性：如果某个单元被访问过，那么不久之后它周围的空间也会被访问。
### 4.3.2 特征
1. 多次性， 无需在作业时一次性全部装入内存，而是允许被分成多次调入内存运行
2. 对换性，无需在作业运行时一直常驻内存，允许在作业的运行过程中，进行换进和换出
3. 虚拟性，从逻辑上扩充内存的容量，用户看到的内存容量，远大于实际的内存容量
### 4.3.3 虚拟技术内存的实现
1. 一定容量的内存和外存
2. 页表机制（或段表机制），作为主要的数据结构
3. 中断机构，当用户程序访问到的部分尚未调入内存，则产生中断
4. 地址变换机构，逻辑地址到物理地址的变换

### 4.3.4 请求分页管理方式
1. 页表机制
- 页号
- 物理块号
- 保护位：允许对该页做何种类型的访问（只读、可读写、）
- 驻留位：指示该页在内存还是在外存
- 访问字段A：记录本页在一段时间内被访问的次数，或多长时间未被访问（用于页面置换算法）
- 修改位M：标识该页在调入内存后收否被修改过
- 外存地址：该页在外存上的地址
2. 缺页中断机构
- 在请求分页系统中，每当要访问的页面不在内存时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成时唤醒），如果内存中有空闲块则分配一个块，将要调入的页装入该块，并修改页表中相应页表项，若此时内存中没有空闲块，则要淘汰某页。（若被淘汰页在内存期间被修改过，则要将其写回外存）
3. 地址变换机构
![](http://note.youdao.com/yws/public/resource/eed1fa7701b0e40871bca24194444756/xmlnote/8E649EF21B8F4CDCB559DDDAE97F147E/15122)

### 4.3.5 页面置换算法（决定应该换入哪页，换出哪页）
1. 最佳置换算法（OPT）：选择在最长时间内不在被访问的页面换出。实际上该算法无法使用
2. 先进先出（FIFO）页面置换算法：淘汰最早进入内存的页面
3. 最近最久未使用（LRU）置换算法：选择最长时间未访问的页面淘汰需要TLB实现（硬件支持 双向链表+hash
4. 时钟（CLOCK）（Not Recently Used，NRU）置换算法：循环扫描缓冲区，像时钟的针一样转动。给每一帧关联一个使用位。当缺页错误出现时，首先检查指针指向的页面，如果R位是0就淘汰页面，并把新页面插入，然后表针前移；如果R位是1就清零前移。和第二次算法性能差不多，花费更少时间，实际使用的算法.
5. 工作集置换算法，一个进程当前使用的页面的集合称为工作集。
6. 工作集时钟页面置换算法
7. LFU（ Least Frequently Used，最不频繁使用）两个双向链表+hash
8. 第二次机会页面置换算法：在FIFO基础上增加使用位，如果链首使用位是1则清零加入链尾。相比FIFO性能大大提高
